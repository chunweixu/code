{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "# 读取训练数据到数据矩阵和类别标签列表\n",
    "def loadDataSet(filename):\n",
    "    dataMat = []; labelMat = []\n",
    "\n",
    "    # 打开文件\n",
    "    fr = open(filename)\n",
    "\n",
    "    # 遍历数据文件每一行\n",
    "    for line in fr.readlines():\n",
    "\n",
    "        # 根据制表符切分每一行的数据\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr =[]\n",
    "\n",
    "        # 将22项数据都去进lineArr列表\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "\n",
    "        # 添加到矩阵和类别标签列表\n",
    "        dataMat.append(lineArr)\n",
    "\n",
    "        # 第22列为类别\n",
    "        labelMat.append(float(currLine[21]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "# 分类函数，通过输入的阈值参数进行分类\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "\n",
    "    # 初始化分类结果为1\n",
    "    retArray = ones((shape(dataMatrix)[0],1))\n",
    "\n",
    "    # 判断阈值中条件\n",
    "    if threshIneq == 'lt':\n",
    "        # 条件为小于等于阈值的类别为-1\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "\n",
    "# 单层决策树生成函数，找到并建立数据集上的最佳的单层决策树\n",
    "def buildStump(dataArr,classLabels,D):\n",
    "    # 构建输入数据矩阵和类别标签矩阵\n",
    "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
    "    m,n = shape(dataMatrix)\n",
    "\n",
    "    # 创建bestStump用于存储最佳单层决策树的相关信息\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
    "\n",
    "    # 初始化错误率为无穷大\n",
    "    minError = inf\n",
    "\n",
    "    # 循环遍历数据集的所有特征\n",
    "    for i in range(n):\n",
    "        # 通过计算数据最大最小值来获取步长\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "\n",
    "        # 在当前特征对应的数据上进行遍历\n",
    "        for j in range(-1,int(numSteps)+1):\n",
    "\n",
    "            # 再大于和小于之间切换不等式条件\n",
    "            for inequal in ['lt', 'gt']:\n",
    "\n",
    "                # 得到本次执行的阈值\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "\n",
    "                # 获得数据分类结果\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)\n",
    "\n",
    "                # 计算错误率\n",
    "                errArr = mat(ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr\n",
    "\n",
    "                # 判断加权错误率是否小于当前的最小错误率\n",
    "                if weightedError < minError:\n",
    "                    # 更新决策树\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    # 返回最佳单层决策树\n",
    "    return bestStump,minError,bestClasEst\n",
    "\n",
    "# AdaBoost训练过程，返回训练结果为弱分类器\n",
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "\n",
    "    # 初始化要返回的弱分类器列表\n",
    "    weakClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "\n",
    "    # 初始化D值，赋予相等的权重\n",
    "    D = mat(ones((m,1))/m)\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "\n",
    "    # 开始训练迭代\n",
    "    for i in range(numIt):\n",
    "\n",
    "        # 获取最佳单层决策树，最小错误率和估计的类别向量\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)\n",
    "\n",
    "        # 计算alpha值，为本次分类器输出结果的权重\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "\n",
    "        # 将本次获得的决策树存入分类器列表\n",
    "        weakClassArr.append(bestStump)\n",
    "\n",
    "        # 计算下一次迭代的D值\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T,classEst) \n",
    "        D = multiply(D,exp(expon))\n",
    "        D = D/D.sum()\n",
    "\n",
    "        # 计算总分类器的错误率，aggClassEst保存运行时的类型估计值\n",
    "        aggClassEst += alpha*classEst\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print \"total error: \",errorRate\n",
    "\n",
    "        # 如果错误率已经为0则退出迭代\n",
    "        if errorRate == 0.0: break\n",
    "\n",
    "    # 返回弱分类器\n",
    "    return weakClassArr\n",
    "\n",
    "# AdaBoost分类函数，根据训练得到的弱分类器对数据进行分类\n",
    "def adaClassify(datToClass,classifierArr):\n",
    "    # 初始化输入数据\n",
    "    dataMatrix = mat(datToClass)\n",
    "    m = shape(dataMatrix)[0]\n",
    "\n",
    "    # 初始化aggClassEst为全0向量\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "\n",
    "    # 依次使用每个弱分类器\n",
    "    for i in range(len(classifierArr)):\n",
    "\n",
    "        # 使用弱分类器得到类别估计值\n",
    "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],\\\n",
    "                                 classifierArr[i]['thresh'],\\\n",
    "                                 classifierArr[i]['ineq'])\n",
    "\n",
    "        # 输出的类别乘以权重后累加到aggClassEst上\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "\n",
    "    # 返回sign()函数处理过的aggClassEst值即为预计的类别\n",
    "    return sign(aggClassEst)\n",
    "\n",
    "# 测试算法\n",
    "def adaTest():\n",
    "    # 读取训练数据\n",
    "    trainingSet, trainingLabels = loadDataSet('horseColicTraining2.txt')\n",
    "\n",
    "    # 训练算法\n",
    "    classifierArray = adaBoostTrainDS(trainingSet, trainingLabels)\n",
    "\n",
    "    # 测试条目数量\n",
    "    numTestVec = 67.0\n",
    "\n",
    "    # 读取测试数据\n",
    "    testSet, testLabels = loadDataSet('horseColicTest2.txt')\n",
    "\n",
    "    # 使用分类器进行预测\n",
    "    prediction10 = adaClassify(testSet, classifierArray)\n",
    "\n",
    "    # 对比分类预测结果及真实结果并记录错误率\n",
    "    errArr = mat(ones((67,1)))\n",
    "\n",
    "    # 矩阵计算得到判断出错的条目数\n",
    "    errorCount = errArr[prediction10!=mat(testLabels).T].sum()\n",
    "\n",
    "    # 计算并输出错误率\n",
    "    errorRate = (float(errorCount)/numTestVec)\n",
    "    print \"the error rate of this test is: %f\" % errorRate\n",
    "    return errorRate\n",
    "\n",
    "\n",
    "adaTest()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
